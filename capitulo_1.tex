\chapter{Introducción}

La música es el idioma universal, no importa en qué lugar físico nos encontremos, todos alguna vez hemos escuchado una canción que se nos queda grabada en la cabeza por mucho tiempo. En ocasiones nos preguntamos cómo es que el autor compuso esa canción.

Existen muchos géneros musicales, cada uno cuenta con sus propias reglas, ritmos y sonidos característicos, por lo que los compositores que se dedican a crear nuevas canciones para cada genero en especifico, deben de tener una gran noción acerca del mismo asi como sus generalidades. Es por eso que nos ponemos a pensar si una computadora es capaz aprender a reconocer las generalidades de un genero musical y generar nuevas piezas musicales en base a esto.

Si bien es cierto el componer una canción es un arte, las canciones se pueden interpretar en forma matemática, esto nos abre la posibilidad de usar algoritmos computacionales para la creación de nuevas canciones.

\section{Descripción del Problema}

Los principales problemas en la composición musical son: la falta de ideas y el tiempo requerido para la composición.

Existen compositores que a lo largo del tiempo no les gusta explorar nuevas formas o ritmos musicales y eso ocasiona que sus composiciones sean muy similares entre si.

El tiempo requerido para la creación de una nueva canción es muy variado, ya que depende del género, el número de instrumentos y la complejidad de la composición. 

En este trabajo se busca usar un algoritmo computacional, que nos permita generar nuevas canciones de una manera más rápida y sencilla.

\section{Objetivos}
\subsection{Objetivo General}

Creación de un programa que use algoritmos para servir de apoyo para composición musical.

\subsection{Objetivos Específicos}
\begin{enumerate}
  \item Implementar una red neuronal de Deep Learning que sea capaz de crear melodías y armonías musicales en guitarra.
  \item Implementar una red neuronal de Deep Learning que sea capaz de crear melodías musicales en bajo eléctrico.
  \item Conjuntar la salida de las redes neuronales para generar un solo archivo de audio.
  \item Verificar la Tonalidad de la canción resultante.
  \item Comparar las diferentes arquitecturas.
\end{enumerate}

\section{Justificación}

El uso de algoritmos de Deep Learning en la música no es algo nuevo, sin embargo, existen muchas áreas de oportunidad en cuestión de la implementación de estos algoritmos.

En el articulo ''Deep Learning Techniques for Music Generation - A Survey'' \cite{DBLP:journals/corr/abs-1709-01620} podemos observar diferentes maneras para crear música con redes neuronales de Deep Learning. Este es uno de los trabajos mas completos que existen hasta la fecha. Los autores de este articulo comparan diferentes estilos de redes (CNN, RNN y generativas), para ver cual es la que mejor para creación musical. Aunque es un articulo muy completo no se aborda como hacer que las redes aprendan a distinguir tonalidades.

El articulo ''Deep Learning for Music'' \cite{DBLP:journals/corr/HuangW16} presenta una buena forma para la creación de armonías y melodías musicales utilizando redes de Deep Learning y archivos en formato MIDI. En este trabajo hacen falta maneras para validar la salida musical.

La mayor parte de los trabajos en esta área están basados en melodías y armonías de piano, sin embargo es interesante experimentar con otros instrumentos, ya que cada uno cuenta con su propia manera de interpretar una pieza musical.

Lo que se pretende en esta investigación es tener una manera fácil y rápida para la creación de nuevas composiciones musicales de guitarra y bajo.

\section{Delimitación}

Este proyecto se centrara en crear melodías y armonías musicales de guitarra y bajo eléctrico por lo que no se analizaran otros instrumentos.

Las nuevas canciones creadas por estos algoritmos no buscan ser ideas finales de composición, la única intensión es crear una serie de ideas para nuevas canciones.

La base de datos usada para entrenar a la red neuronal consta de canciones de genero rock y pop unicamente, no se entrenara la red para reconocer y generar canciones de otros géneros musicales.

\section{Organización de la Tesis}

Esta tesis se divide en varios capítulos, los cuales se describen a continuación.

\begin{itemize}
	\item \textbf{Capitulo 1.-} Se presenta una descripción del problema, justificación, delimitación y antecedentes históricos de la investigación.
	\item \textbf{Capitulo 2.-} Contiene el marco teórico de las redes neuronales y su clasificación. 
	\item \textbf{Capitulo 3.-} Aborda el marco teórico musical, todos los conceptos básicos para interpretar y leer música.
	\item \textbf{Capitulo 4.-} Se muestra el desarrollo del proyecto, la arquitectura y los componentes del sistema.
	\item \textbf{Capitulo 5.-} Contiene los resultados de las diferentes etapas del proyecto.
	\item \textbf{Capitulo 6.-} Se muestran las conclusiones del proyecto, así como también los trabajos futuros que podrían realizarse.
\end{itemize}

\section{Antecedentes históricos}

A lo largo del tiempo han surgido varios estudios referentes al uso de algoritmos de Deep Learning con la música, a continuación se presentan algunos de los artículos mas relevantes en este tema:

\subsection{Unsupervised Feature Learning for Audio Classification Using Convolutional Deep Belief Networks \cite{Lee:2009:UFL:2984093.2984217}}

''En los últimos años, los enfoques de Deep Learning han ganado un gran interés como una forma de construir representaciones jerárquicas a partir de datos sin etiquetar. Sin embargo, según nuestro conocimiento, estos enfoques de Deep Learning no se han estudiado exhaustivamente para datos auditivos. En este documento, aplicamos redes de creencias profundas convolucionales a los datos de audio y los evaluamos empíricamente en varias tareas de clasificación de audio. Para el caso de datos de voz, mostramos que las características aprendidas corresponden a teléfonos / fonemas. Además, nuestras representaciones de funciones entrenadas a partir de datos de audio sin etiquetar muestran un rendimiento muy bueno para múltiples tareas de clasificación de audio. Esperamos que este documento inspire más investigación sobre los enfoques de aprendizaje profundo aplicados a una amplia gama de tareas de reconocimiento de audio.''

\subsection{Feature Learning and Deep Architectures: New Directions for Music Informatics \cite{Humphrey:2013:FLD:2590112.2590133}}

''A medida que buscamos avanzar en el estado del arte en informática de música basada en contenido, hay un sentido general de que el progreso se está desacelerando en todo el campo. En una inspección más cercana, las trayectorias de rendimiento en varias aplicaciones revelan que este es realmente el caso, lo que plantea algunas preguntas difíciles para la disciplina: ¿por qué nos estamos desacelerando y qué podemos hacer al respecto? Aquí, nos esforzamos por abordar estas dos preocupaciones. Primero, revisamos críticamente el enfoque estándar para el análisis de la señal de música e identificamos tres deficiencias específicas de los métodos actuales: el diseño de características artesanal es subóptimo e insostenible, el poder de las arquitecturas poco profundas es fundamentalmente limitado y el análisis a corto plazo no puede codificar musicalmente estructura significativa Reconociendo los avances en otros dominios perceptivos de inteligencia artificial, ofrecemos que el aprendizaje profundo tiene el potencial de superar cada uno de estos obstáculos. A través de argumentos conceptuales para el aprendizaje de características y arquitecturas de procesamiento más profundas, demostramos cómo los modelos de procesamiento profundo son extensiones más poderosas de los métodos actuales y por qué ahora es el momento de este cambio de paradigma. Finalmente, concluimos con una discusión de los desafíos actuales y el impacto potencial para motivar aún más una exploración de esta área de investigación prometedora.''

\subsection{Improving Content-based and Hybrid Music Recommendation Using Deep Learning \cite{Wang:2014:ICH:2647868.2654940}}

''Los sistemas de recomendación de música basados ??en contenido existentes suelen emplear un enfoque \ textit {two-stage}. Primero extraen características de contenido de audio tradicionales como los coeficientes cepstral de frecuencia de Mel y luego predicen las preferencias del usuario. Sin embargo, estas características tradicionales, originalmente no creadas para la recomendación de música, no pueden capturar toda la información relevante en el audio y, por lo tanto, limitar el rendimiento de la recomendación. Usando un modelo novedoso basado en una red de creencias profundas y un modelo gráfico probabilístico, unificamos las dos etapas en un proceso automatizado que aprende simultáneamente las características del contenido de audio y hace recomendaciones personalizadas. Comparado con los modelos basados en Deep Learning existentes, nuestro modelo supera a los de las etapas de arranque en caliente y de arranque en frío sin depender del filtrado colaborativo (CF). Luego presentamos un método híbrido eficiente para integrar a la perfección las características aprendidas automáticamente y la CF. Nuestro método híbrido no solo mejora significativamente el rendimiento de la FQ, sino que también supera el método híbrido basado en características tradicionales.''
\newpage

\subsection{Deep Learning for Music \cite{DBLP:journals/corr/HuangW16}}

''Nuestro objetivo es poder construir un modelo generativo a partir de una arquitectura de red neuronal profunda para intentar crear música que tenga armonía y melodía y que sea pasable como música compuesta por humanos. El trabajo anterior en la generación de música se ha centrado principalmente en crear una sola melodía. El trabajo más reciente sobre el modelado de música polifónica, centrado alrededor de la estimación de densidad de probabilidad de series de tiempo, ha logrado cierto éxito parcial. En particular, ha habido mucho trabajo basado en redes neuronales recurrentes combinadas con máquinas de Boltzmann restringidas (RNN-RBM) y otros modelos similares basados en energía recurrente. Sin embargo, nuestro enfoque es realizar el aprendizaje y la generación de extremo a extremo solo con redes neuronales profundas.''

\subsection{End-to-end learning for music audio tagging at scale \cite{DBLP:journals/corr/abs-1711-02520}}

''La falta de datos tiende a limitar los resultados de la investigación de Deep Learning, especialmente cuando se trata de acumulaciones de aprendizaje de extremo a extremo que procesan datos sin procesar, como las formas de onda. En este estudio, 1.2M pistas comentadas con etiquetas musicales están disponibles para entrenar a nuestros modelos de extremo a extremo. Esta gran cantidad de datos nos permite explorar sin restricciones dos paradigmas de diseño diferentes para el etiquetado automático de música: modelos sin supuestos: el uso de formas de onda como entrada con filtros convolucionales muy pequeños; y modelos que se basan en el conocimiento del dominio: espectrogramas log-mel con una red neuronal convolucional diseñada para aprender las características tímbricas y temporales. Nuestro trabajo se centra en estudiar cómo funcionan estos dos tipos de arquitecturas profundas cuando se dispone de conjuntos de datos de tamaño variable para la capacitación: el MagnaTagATune (canciones de 25 k), el conjunto de datos de la canción Million (canciones de 240 k) y un conjunto de datos privado de 1,2 millones de canciones. Nuestros experimentos sugieren que las suposiciones del dominio de la música son relevantes cuando no hay suficientes datos de entrenamiento disponibles, lo que demuestra que los modelos basados en formas de onda superan a los basados en espectrogramas en escenarios de datos a gran escala.''

\subsection{Deep Learning Techniques for Music Generation - A Survey \cite{DBLP:journals/corr/abs-1709-01620}}

''Este documento es una encuesta y un análisis de diferentes formas de utilizar el Deep Learning (redes neuronales artificiales profundas) para generar contenido musical.''

''Proponemos una metodología basada en cinco dimensiones para nuestro análisis: - Objetivo - ¿Qué contenido musical se generará? Por ejemplo, melodía, polifonía, acompañamiento y contrapunto: ¿para qué destino y para qué uso? Para ser realizado por un humano (s) o por una máquina. - Representación - ¿Cuáles son los conceptos a manipular? Por ejemplo, la forma de onda, el espectrograma, la nota, el acorde, el medidor y el tiempo: ¿qué formato se utilizará? Por ejemplo, MIDI, piano roll y texto. ¿Cómo se codificará la representación? Por ejemplo, escalar, one-hot y many-hot. - Arquitectura - ¿Qué tipo de red neuronal profunda se va a utilizar? Por ejemplo, red feedforward, red recurrente, autocodificador y redes adversas generativas. - Retos - ¿Cuáles son las limitaciones \ índice y desafíos abiertos? Por ejemplo, variabilidad, interactividad y creatividad. - Estrategia - ¿Cómo modelamos y controlamos el proceso de generación? Por ejemplo, avance en un solo paso, avance en el decodificador, manipulación de muestreo y entrada.
Para cada dimensión, realizamos un análisis comparativo de varios modelos y técnicas y proponemos una tipología multidimensional tentativa. Esta tipología es de abajo hacia arriba, basada en el análisis de muchos sistemas existentes basados en deep learning para la generación de música seleccionados de la literatura relevante. Estos sistemas se describen en esta encuesta / análisis y se utilizan para ejemplificar las diversas opciones de objetivos, representación, arquitectura, desafíos y estrategias. La parte final del documento incluye algunas discusiones y algunas perspectivas.''

''Este artículo es una versión simplificada (DRM débil) del siguiente libro: Jean-Pierre Briot, Gaetan Hadjeres y Francois Pachet, Técnicas de aprendizaje profundo para la generación de música, Síntesis computacional y Sistemas creativos, Springer Nature, 2019.''
